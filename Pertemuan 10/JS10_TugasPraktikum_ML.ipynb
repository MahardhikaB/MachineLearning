{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKMCiQyaXJ_f"
      },
      "source": [
        "**Import TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVb53LJJOXtG"
      },
      "outputs": [],
      "source": [
        "# Mengimpor TensorFlow, framework untuk machine learning dan deep learning.\n",
        "import tensorflow as tf\n",
        "\n",
        "# Mengimpor NumPy, library yang sering digunakan untuk operasi numerik.\n",
        "import numpy as np\n",
        "\n",
        "# Mengimpor modul os untuk berinteraksi dengan sistem operasi.\n",
        "import os\n",
        "\n",
        "# Mengimpor modul time untuk mengukur waktu eksekusi.\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ex5rQICXJ_g"
      },
      "source": [
        "**Download Dataset Shakespeare**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYvcpKYCOe6f"
      },
      "outputs": [],
      "source": [
        "# Mengunduh file 'shakespeare.txt' dari URL yang diberikan dan menyimpannya di path yang ditentukan.\n",
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et2vMNRdXJ_h"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ18RZ7GOzwK",
        "outputId": "21fca257-4e7f-4842-fcf2-03577215b54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membaca file teks 'shakespeare.txt' dalam mode baca biner (rb), kemudian mendekode teksnya menggunakan utf-8.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# Menampilkan panjang teks yang telah dibaca dalam jumlah karakter.\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxyn-IzBO7Pd",
        "outputId": "b794828d-9118-41c3-82f5-e4c70240aa62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan 250 karakter pertama dari teks.\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msSNwl5MO9Xn",
        "outputId": "7e3b6672-e02d-44a8-9dbd-4572adc2255c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Mencari karakter-karakter unik dalam teks dan mengurutkannya.\n",
        "vocab = sorted(set(text))\n",
        "# Menampilkan jumlah karakter unik yang ada dalam teks.\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3e7k7UkXJ_j"
      },
      "source": [
        "## Olah Teks\n",
        "**Vectorize Tekz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acka3jZJO_qc",
        "outputId": "1120fea4-c2c4-4bb9-80b2-07935bb8d138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Membuat daftar teks contoh yang berisi dua string.\n",
        "example_texts=['abcdefg','xyz']\n",
        "# Menggunakan tf.strings.unicode_split untuk memecah teks menjadi karakter unicode.\n",
        "chars=tf.strings.unicode_split(example_texts,input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dv-3hzZPFZW"
      },
      "outputs": [],
      "source": [
        "# Membuat kamus (lookup) untuk menghubungkan karakter dengan ID numerik.\n",
        "ids_from_chars=tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTyA0NqTPK9V",
        "outputId": "93804af2-9df6-46ac-ec86-a9dd84e79bab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Mengonversi karakter-karakter dalam variabel `chars` menjadi ID numerik.\n",
        "ids=ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEJ_zXxFPRWI"
      },
      "outputs": [],
      "source": [
        "# Membuat kamus (lookup) untuk menghubungkan ID numerik kembali ke karakter.\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp5pUz0rPT3T",
        "outputId": "cb5fce2d-3af4-4fdc-a970-f38787dc57f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi ID numerik kembali menjadi karakter.\n",
        "chars=chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR1ZBiosPW7Q",
        "outputId": "fcdfebf3-3da5-4dbc-ce6f-2b868b9eaabe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menggabungkan karakter-karakter dalam `chars` menjadi string tunggal.\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I9qI11jPZct"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan fungsi untuk mengonversi ID numerik menjadi teks.\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iNrK3zlPfQc"
      },
      "source": [
        "# Prediksi\n",
        "**Membuat Training Set dan Target**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwJ6jfGpPgxx",
        "outputId": "8e62237d-0272-4c42-b691-99d8a36aa9f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi seluruh teks menjadi urutan ID numerik.\n",
        "all_ids=ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZY7VCePmJt"
      },
      "outputs": [],
      "source": [
        "# Membuat dataset TensorFlow dari tensor ID numerik.\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hgmwJlWPoyp",
        "outputId": "af1a1da4-6d1a-492a-a131-40f37065d241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "# Mengambil 10 urutan karakter dari dataset dan mengonversi kembali ke teks.\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MrJjrgcPunL"
      },
      "outputs": [],
      "source": [
        "# Mengelompokkan urutan ID numerik menjadi urutan yang lebih pendek dengan panjang tertentu.\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9gNBGsXPydl",
        "outputId": "496d2a29-5c25-403a-f426-9d6c749b3596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "# Menampilkan satu urutan yang telah dibagi.\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzdW2AA-Pzza",
        "outputId": "483fba4f-a14c-4cc5-a9f2-83cf3fa2ed00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS4C3uG_P5eb"
      },
      "outputs": [],
      "source": [
        "# Menggunakan fungsi split_input_target untuk memisahkan input dan target.\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhucZIEXQCPf",
        "outputId": "1abb5475-b885-453a-b4f3-64bdba7af7bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mengilustrasikan bagaimana fungsi split_input_target bekerja.\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xori0H4NQEEp"
      },
      "outputs": [],
      "source": [
        "# Mengaplikasikan fungsi split_input_target ke semua urutan dalam dataset.\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba7ubXxEQJq1",
        "outputId": "c82138bc-7170-48bb-adaa-520626e45dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan contoh input dan target dari dataset.\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQu6cut9QSYR"
      },
      "source": [
        "**Membuat  Batch Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnnbUYpAQQcZ",
        "outputId": "c80c9bea-7a4c-45f1-886b-bc679f0e41f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menentukan BATCH_SIZE (ukuran batch) untuk pelatihan model.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Menentukan BUFFER_SIZE untuk proses pengacakan dataset.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Menyiapkan dataset dengan langkah-langkah berikut:\n",
        "# 1. Melakukan pengacakan elemen-elemen dataset menggunakan BUFFER_SIZE.\n",
        "# 2. Mengelompokkan dataset menjadi batch dengan ukuran BATCH_SIZE dan menjatuhkan sisa jika ada.\n",
        "# 3. Menggunakan prefetch untuk mengoptimalkan proses pembacaan data.\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idd8UpHvXJ_p"
      },
      "source": [
        "## Membuat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMW5AkEBQXeX"
      },
      "outputs": [],
      "source": [
        "# Menentukan ukuran vocab, dimensi embedding, dan jumlah unit RNN dalam model.\n",
        "\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTmwo9n1QaCS"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan kelas MyModel yang akan digunakan sebagai model untuk pemrosesan teks.\n",
        "\n",
        "# Kode ini mendefinisikan kelas MyModel yang merupakan turunan dari tf.keras.Model.\n",
        "# Model ini terdiri dari beberapa lapisan, termasuk lapisan embedding (untuk merepresentasikan karakter dalam vektor), lapisan GRU (Recurrent Unit Gate) yang digunakan untuk memproses urutan, dan lapisan dense yang digunakan untuk menghasilkan output.\n",
        "# Model ini memiliki metode call, yang digunakan untuk menggambarkan aliran data melalui model. Model ini memiliki fleksibilitas dalam mengembalikan output dan/atau status internal.\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGe6dv3lQcsu"
      },
      "outputs": [],
      "source": [
        "# Membuat model MyModel dengan parameter yang telah ditentukan sebelumnya.\n",
        "# membuat model MyModel dengan parameter-parameter yang telah ditentukan sebelumnya, seperti ukuran vocab, dimensi embedding, dan jumlah unit RNN.\n",
        "# Model ini siap untuk digunakan dalam pelatihan atau pengujian.\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnSprzQAQfhx"
      },
      "source": [
        "## Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eZnmax6QhbL",
        "outputId": "8009b3d8-d0ab-4275-add1-80dd6b840da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Mengambil contoh batch input dan target dari dataset.\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgskB_21Qmhe",
        "outputId": "1ad5674c-7ab1-4855-f678-102adb4b180f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  16896     \n",
            "                                                                 \n",
            " gru_2 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan ringkasan (summary) dari model.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vr-rTxLQoqt"
      },
      "outputs": [],
      "source": [
        "# Mengambil indeks karakter yang diambil secara acak dari prediksi model.\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtGv2J7VQt_8",
        "outputId": "f59d591d-28c0-47d8-dd8c-726a6d2861d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([57, 48,  6, 58, 39,  1,  4, 24,  6, 53, 12,  9, 54, 64, 56, 33, 30,\n",
              "       21, 56, 26, 35, 31, 31, 33, 41, 48, 58, 42, 22, 43,  1, 28, 55, 54,\n",
              "       42, 13,  1, 44, 59,  2, 16, 48, 65, 31, 62,  5, 56, 20, 35, 46,  5,\n",
              "       39, 13, 43, 54, 20, 64, 54, 14,  7, 65, 34,  7, 48, 30, 16, 24, 14,\n",
              "        3, 21,  1, 49, 10, 64, 45,  9,  4,  3, 24, 42,  1, 28, 30,  3, 18,\n",
              "       38, 50, 23, 17, 27, 14, 25, 56, 42, 30, 39,  8,  0, 28, 62])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menampilkan index karakter yang diambil secara acak\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WWEhymhRQvR",
        "outputId": "cd61144b-3330-49ff-b607-34d3a35a075b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'your youth,\\nBut mine shall be a comfort to your age.\\nThe loss you have is but a son being king,\\nAnd '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"ri'sZ\\n$K'n;.oyqTQHqMVRRTbiscId\\nOpoc?\\net CizRw&qGVg&Z?doGyoA,zU,iQCKA!H\\nj3yf.$!Kc\\nOQ!EYkJDNALqcQZ-[UNK]Ow\"\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan input dan prediksi karakter selanjutnya.\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQASjWVRYiM"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6knrcTUiXJ_x"
      },
      "source": [
        "**Menambahkan optimizer dan fungsi loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSvCpcRGRarj"
      },
      "outputs": [],
      "source": [
        "# loss function untuk pelatihan model yang digunakan untuk tugas seperti klasifikasi atau pemrosesan bahasa alami.\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIHMaJL_SF63",
        "outputId": "0b39b4d7-611c-45b0-ed39-e7a6ab50cc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1888685, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Menghitung nilai kerugian (loss) model dengan fungsi SparseCategoricalCrossentropy.\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVZGsvfASMey",
        "outputId": "cd3ec5e5-f09a-4964-b365-023c9a012434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.94813"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# untuk menghitung eksponensial dari nilai rata-rata kerugian (mean loss) dalam bentuk tensor.\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb_FWJPNSOle"
      },
      "outputs": [],
      "source": [
        "# Menggunakan optimizer 'adam' dan loss yang telah dihitung sebelumnya.\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TotX5OawSWjf"
      },
      "source": [
        "**Konfigurasi Checkpoints**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYEbwIPxScC7"
      },
      "outputs": [],
      "source": [
        "# Menyiapkan direktori dan nama file checkpoint untuk menyimpan model.\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "# Membuat callback untuk menyimpan bobot model saat pelatihan.\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqUFGReHXJ_y"
      },
      "source": [
        "**Melakukan proses Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF5on2E9Segs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10 # Menentukan jumlah EPOCHS (iterasi pelatihan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfXyRox4Sotb",
        "outputId": "ebd7e075-bd75-4b97-dc0c-3e90d77cf3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 13s 57ms/step - loss: 2.7047\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.9889\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.7093\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.5468\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.4476\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3796\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3280\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2818\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2414\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2025\n"
          ]
        }
      ],
      "source": [
        "# Memulai pelatihan model dengan dataset dan callback untuk menyimpan bobot.\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkstlxn6XJ_z"
      },
      "source": [
        "## Generate Teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAINBCInCGcn"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan kelas OneStep yang bertindak sebagai model untuk menghasilkan teks karakter demi karakter.\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "   # Membuat masker untuk mencegah generasi karakter \"[UNK]\" (unknown) yang tidak diinginkan.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Memasang -inf pada setiap indeks yang tidak diinginkan.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # menyesuaikan bentuk dengan vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Mengonversi string menjadi token ID.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "   # Menjalankan model.\n",
        "    # predicted_logits.shape adalah [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "   # Hanya menggunakan prediksi terakhir.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Menerapkan masker prediksi: mencegah \"[UNK]\" dari dihasilkan.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Mencoba output logits untuk menghasilkan token ID.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Mengonversi dari token ID menjadi karakter.\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Mengembalikan karakter dan status model.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NFxNn81CeV8"
      },
      "outputs": [],
      "source": [
        "# Membuat instance dari model OneStep.\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20tpxyACXu3",
        "outputId": "f855e0b5-0a29-454b-b5a3-05dd731a168f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "why look their eyes?\n",
            "\n",
            "First Lord:\n",
            "Why, over hast thou with the welcome of the pardon.\n",
            "\n",
            "YORK:\n",
            "Even for a little, made me from your friends\n",
            "And traitoble that more pain of our amils.\n",
            "\n",
            "BAPTISTA:\n",
            "Madam! if the else\n",
            "A wime of Hereford sirs a grave Master cousin.\n",
            "\n",
            "Second Ungains when he did prove\n",
            "A sisterhood of this milder of them.\n",
            "\n",
            "LUCENTIO:\n",
            "\n",
            "LADY CAPULET:\n",
            "No, sirt, a nobleman, Lord Northumberland,--\n",
            "What nourish? 'Fail in person whether do loud could\n",
            "Absence mides, our circles fools, as you\n",
            "would not have your pettice on the head that yet quench you\n",
            "To say to tell her counsellor mouth: tears barmands;\n",
            "And if a man go town: he hath drait much controvery of it.\n",
            "Thus live the durthes for resolved: their eyes hand so read\n",
            "With one as you myselves faults, but as sound?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Ay, there is the pale and think the idle deaths\n",
            "As well as so smolent of you this married breath,\n",
            "'tis Richard and beat dreaming?\n",
            "\n",
            "KING RICHARD III:\n",
            "We are like the wrinkles with him!\n",
            "\n",
            "SCANLECONT:\n",
            "God gave him  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.7905681133270264\n"
          ]
        }
      ],
      "source": [
        "# Generasi teks karakter demi karakter dengan model OneStep.\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "# Kode diatas menghasilkan teks karakter demi karakter menggunakan model OneStep. Mulai dari karakter \"ROMEO:\", model menghasilkan karakter berikutnya dengan mengikuti probabilitas distribusi yang telah dipelajari selama pelatihan.\n",
        "\n",
        "# Menampilkan hasil generasi teks.\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dCLQUClCp1O",
        "outputId": "62a2e328-8519-42e9-c1cb-0d2aa0b11a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nNurse, one that set of inclined, hither too\\nmad poverty senses; as much given her uncles drown\\nHim prosperous plant but of aften ease,\\neven he have stood and Darentain lies\\nAnd when I dare need no rearianing; the dutt\\nbeen affection of a royal queen!\\n\\nFLORIZEL:\\nI do; with him the chamory\\nThe times of my sisters favour of their\\na couched spite of right field.\\n\\nWARWICK:\\nWas eye, my boy, let us swallow well they did:\\nThe people is much patience, that also explecting embrace\\nWhereof shall enter there is farnest usmes ne\\nMartingare that sworn in sulf,\\nHer title is already things and the world:\\nGive diving yourself his wifes hoties: they all to die\\nAs a time indeed to see a beforn.\\n\\nSecond Musician:\\nTranio, thou aftice,\\nThe hungry gape of all\\nthe devil. How now! why come you of.\\n\\nSecond Murderer:\\nThere's the best; and after two and the ord\\nBut only so faster, I have with these season\\nThe Volsces from your gamours' doubled to his\\ncannot, there to make one heart\\nTo Richard trusper, slew Dedec\"\n",
            " b\"ROMEO:\\nThe idlent groving lord; a dyill hear not help\\nTrembling them on; for all your conquest I winder,\\nGrom hereabthes-grandfully: your guests, enjoy--\\n\\nLUCIO:\\nI see these hours\\nMine honour of his: every love, another\\nAnd unhappy bodyess. When was not heavy\\nMaster lourers of the world.\\n\\nISABELLA:\\nI do beseech you, if you put may-near\\nVoot well makes reachy son, being deliver'd\\nspeaking sudves, Take nothing but Pomp you here.\\nWhen, I beseech you. If you perching tome,\\nHide men need within either fall thee in!\\n\\nBUCLIDF:\\nYea, but one worder-of my knee,\\nAs the office Vilentiness how\\nLook you our despent best? They never draw you find\\nTrample and seen a parlonge there,\\nShould not waited with the champtians fair of Sick.\\nRivers madam.\\n\\nCAPULET:\\nMy fortune should not have ellested counce for then read;\\nOr else to send the crown conference come,\\nTo do it begs as vengeable, which in thy\\nglorious Duke of York the drunken faults\\nAgainst any wayst fog out my masters;\\nGood nignts from these wills over-\"\n",
            " b\"ROMEO:\\nI'll know him my heart's last, all on office\\nTo early think o' the east.\\n\\nJLOUCESTER:\\nGo, keep your loss?\\n\\nNORTHUMBERLAND:\\nA myst\\nOx like unknown that our dissemminies,\\nWhich eitanders set like peace?\\nO, he shall hold you now; for of him that\\nstone sounds in me agoness.\\n\\nCURTES:\\nWe could attend you go to-morrow:\\nThe innatch made tramely fights than you another?\\nIn, being the hopes of tears as you are\\nread, and lost atcountence and furn and cannators\\nby out word thereof our sudden man I have togetee\\nThat has a mank on of it? I am stringed the\\nbody on the lawful keeps. Doth on the\\nsink before I rest be my bown: he is the eye\\nWhom he had heard'st of willing, kings yield.\\nSurse, that you but set it here loves yield to him our loving eme.\\nIt sad you for the Grauntage gafes,\\nOne pinch'd by the mirdorys of yours.\\n\\nKING RICHARD III:\\nHow! that is much therething you should burcy:\\nO, that the letters of won held I serewhal\\nI see the blind, and the island condemn'dous\\nere is poor with me soundin\"\n",
            " b\"ROMEO:\\nThis dares am nobles, good life! didness up he die tood favour\\nThat our charge and thrives of confined fortund even taste\\nThat blame before this redress of my atter:\\nIf so the gods good cannot but their honesty bired.\\n\\nBIANCA:\\nThis bud confessol is been tongues,\\nAnd tyranny of inhunts that have med\\nFinds with victory grant heavy: yea,\\nI am no pretty of answer?\\nWhat countenance from honour, if you should not\\nconfest thee help me as so good a raggeled and\\nMisfore the turn.\\n\\nROMEO:\\nIf this live, gentle enough! Thus she doth make poor throne,\\nindeed, was struck me in the readful tunk.\\nAcaised the air age of draisperity, and, Montague,\\nHow from envocious seen\\nWhich did out of that owr houses fly good\\nAs 'twere not that do think, kind upon your guests,\\nGod surress yourselves and there is chreading to that garden\\nThan that hear them; which drink! if\\nhe had both as little little, this unknown too hear\\nAs I tell thee what must be plaughted,\\nThat he shall love's rests in thy brown; none.\\nCouse \"\n",
            " b\"ROMEO:\\nBy that the grounds, pinch mine honour.\\n\\nMARIANA:\\nPray, be there to dier upon.\\n\\nJULIET:\\nAy, so we wills keep gown:\\nWhy, when, my lord; why hath pass'd him count-fall, yourselves\\ndare on't: will you be overwapted with mine,\\nSay 'CAPET:\\nWhy, then, and all's fault make gaps as yet.\\n\\nROMEO:\\nHere I could wisdly lie unge.\\nThe devil should, I with you!\\n\\nCATESBURY:\\nThen 'tis full as many lives in us.\\nO, stand alood, have the whither aftle strong? what\\nfon the rock of minister-love slapped me?\\n\\nPage:\\nThou bear'st that you depise; you must come a leap,\\nAnd duty use that vouches the wise officer\\nThe house of goodnalt keep'd, better\\nThe whiteer ribbodness and like younger,\\nOn their deed services that out thee that thy back;\\nThou gartest till the best I did rest, there\\nwere that thinks our butchery, backles, hadsher plunes\\nSuch things that years still, they were sleep of foul\\nIn merrage.\\n\\nSecond Marshal:\\nWhat should I have been in queen? and you have doness need\\nOn him that last I have possible to\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3767802715301514\n"
          ]
        }
      ],
      "source": [
        "# Generasi teks karakter demi karakter dengan model OneStep yang telah dimuat kembali.\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "\n",
        "# Menampilkan hasil generasi teks dengan model yang telah dimuat kembali.\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en_6IVlTXJ_0"
      },
      "source": [
        " Perbedaan utama dengan kode sebelumnya adalah pola awal inputnya. Pada kode sebelumnya, pola awal adalah ROMEO:, sedangkan pada kode ini, pola awal adalah ROMEO: yang diulang sebanyak lima kali. Dengan demikian, dapat dilihat bahwa model yang telah dimuat kembali dapat digunakan untuk menghasilkan teks dari berbagai pola awal yang berbeda, dan hasilnya akan tergantung pada pola awal yang digunakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXcQ5RBKXJ_0"
      },
      "source": [
        "**Mengekspor Model Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQe42yPFCyBH",
        "outputId": "5986c677-429c-434d-816d-8233f5d1cd96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c821bd443a0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan model OneStep ke disk dengan nama 'one_step'.\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "# Memuat model OneStep dari disk dengan nama 'one_step' yang telah disimpan sebelumnya.\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7bxyPQyC1zN",
        "outputId": "c6eb9a30-6727-4153-c039-040001b08285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "The white idwase assurate his folly!\n",
            "The pacress spirition! of my thusb at you,\n",
            "I cannot chysol exc\n"
          ]
        }
      ],
      "source": [
        "# Menginisialisasi variabel states dan next_char.\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "# Melakukan generasi teks karakter demi karakter dengan model yang telah dimuat kembali.\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Menampilkan hasil teks yang dihasilkan oleh model.\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbUas9LGH8Fe"
      },
      "outputs": [],
      "source": [
        "# Membuat subclass kustom dari model MyModel untuk pelatihan kustom.\n",
        "class CustomTraining(MyModel):\n",
        " @tf.function\n",
        " def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-_i8g77XJ_1"
      },
      "source": [
        "Kode diatas mendefinisikan subclass kustom dari model MyModel yang disebut CustomTraining. Subclass ini digunakan untuk melakukan pelatihan kustom. Dalam subclass ini, kita mendefinisikan metode train_step yang menangani langkah pelatihan dengan menghitung gradien, mengoptimasi model, dan mengembalikan informasi kerugian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_VI-e4GJAoq"
      },
      "outputs": [],
      "source": [
        "# Membuat model kustom dengan subclass kustom yang telah dibuat sebelumnya.\n",
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaZAWZYPJFBP"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoVtU0cbXJ_1"
      },
      "source": [
        "Kode diatas menciptakan model kustom dengan menggunakan subclass CustomTraining. Model ini diatur untuk pelatihan dengan optimizer Adam dan loss function SparseCategoricalCrossentropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6rjiw9SJNUn",
        "outputId": "0af7d4c2-1a53-43e1-b66b-cd5334b26edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 14s 58ms/step - loss: 2.6690\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8212e1ae60>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Melakukan pelatihan model selama 1 epoch.\n",
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYFI70d1NRZE",
        "outputId": "6e11b380-8581-4169-910d-127716f0fb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1556\n",
            "Epoch 1 Batch 50 Loss 2.0305\n",
            "Epoch 1 Batch 100 Loss 1.8996\n",
            "Epoch 1 Batch 150 Loss 1.8377\n",
            "\n",
            "Epoch 1 Loss: 1.9623\n",
            "Time taken for 1 epoch 14.36 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7698\n",
            "Epoch 2 Batch 50 Loss 1.7498\n",
            "Epoch 2 Batch 100 Loss 1.7194\n",
            "Epoch 2 Batch 150 Loss 1.6241\n",
            "\n",
            "Epoch 2 Loss: 1.6877\n",
            "Time taken for 1 epoch 11.66 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5910\n",
            "Epoch 3 Batch 50 Loss 1.5358\n",
            "Epoch 3 Batch 100 Loss 1.4736\n",
            "Epoch 3 Batch 150 Loss 1.5427\n",
            "\n",
            "Epoch 3 Loss: 1.5303\n",
            "Time taken for 1 epoch 11.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4295\n",
            "Epoch 4 Batch 50 Loss 1.4686\n",
            "Epoch 4 Batch 100 Loss 1.4214\n",
            "Epoch 4 Batch 150 Loss 1.4383\n",
            "\n",
            "Epoch 4 Loss: 1.4346\n",
            "Time taken for 1 epoch 11.82 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3645\n",
            "Epoch 5 Batch 50 Loss 1.3855\n",
            "Epoch 5 Batch 100 Loss 1.4054\n",
            "Epoch 5 Batch 150 Loss 1.3651\n",
            "\n",
            "Epoch 5 Loss: 1.3680\n",
            "Time taken for 1 epoch 12.25 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3322\n",
            "Epoch 6 Batch 50 Loss 1.3445\n",
            "Epoch 6 Batch 100 Loss 1.2954\n",
            "Epoch 6 Batch 150 Loss 1.3445\n",
            "\n",
            "Epoch 6 Loss: 1.3161\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2334\n",
            "Epoch 7 Batch 50 Loss 1.2477\n",
            "Epoch 7 Batch 100 Loss 1.2783\n",
            "Epoch 7 Batch 150 Loss 1.2949\n",
            "\n",
            "Epoch 7 Loss: 1.2717\n",
            "Time taken for 1 epoch 11.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2261\n",
            "Epoch 8 Batch 50 Loss 1.2292\n",
            "Epoch 8 Batch 100 Loss 1.2052\n",
            "Epoch 8 Batch 150 Loss 1.2494\n",
            "\n",
            "Epoch 8 Loss: 1.2298\n",
            "Time taken for 1 epoch 11.43 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1957\n",
            "Epoch 9 Batch 50 Loss 1.1411\n",
            "Epoch 9 Batch 100 Loss 1.1402\n",
            "Epoch 9 Batch 150 Loss 1.2241\n",
            "\n",
            "Epoch 9 Loss: 1.1888\n",
            "Time taken for 1 epoch 11.56 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.0738\n",
            "Epoch 10 Batch 50 Loss 1.1182\n",
            "Epoch 10 Batch 100 Loss 1.1674\n",
            "Epoch 10 Batch 150 Loss 1.1759\n",
            "\n",
            "Epoch 10 Loss: 1.1486\n",
            "Time taken for 1 epoch 11.64 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Melakukan pelatihan model selama beberapa epoch dengan pengukuran kerugian rata-rata.\n",
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "   start = time.time()\n",
        "\n",
        "   mean.reset_states()\n",
        "   for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "     logs = model.train_step([inp, target])\n",
        "     mean.update_state(logs['loss'])\n",
        "\n",
        "     if batch_n % 50 == 0:\n",
        "       template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "       print(template)\n",
        "\n",
        "   # saving (checkpoint) the model every 5 epochs\n",
        "   if (epoch + 1) % 5 == 0:\n",
        "     model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "   print()\n",
        "   print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "   print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "   print(\"_\"*80)\n",
        "\n",
        "# Menyimpan bobot model setelah pelatihan selesai\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJQAntTwXJ_2"
      },
      "source": [
        "Kode diatas melakukan pelatihan model selama beberapa epoch. Dalam setiap epoch, loss rata-rata diukur dan hasilnya ditampilkan. Model juga akan menyimpan bobotnya setiap 5 epoch menggunakan checkpoint. Setelah pelatihan selesai, bobot model akhir akan disimpan. Hal ini adalah proses pelatihan lengkap yang dapat diulang sesuai kebutuhan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm1jqO2QXJ_2"
      },
      "source": [
        "Dari output diatas menunjukkan bahwa model RNN telah belajar untuk menghasilkan teks yang lebih akurat dan koheren seiring bertambahnya jumlah epoch. Pada epoch pertama, model menghasilkan teks dengan loss sebesar 2.1556. Loss ini menunjukkan bahwa model masih menghasilkan teks yang tidak akurat dan tidak koheren. Namun, pada epoch kesepuluh, model menghasilkan teks dengan loss sebesar 1.1486. Loss ini menunjukkan bahwa model telah belajar untuk menghasilkan teks yang lebih akurat dan koheren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqEn0DW5XJ_2"
      },
      "source": [
        "**Perbedaan kode diatas dengan praktikum 2** <br><br>\n",
        "\n",
        "Dalam konteks kode yang telah diberikan, perbedaan terutama terletak pada penggunaan model dan pendekatan pelatihan khusus yang digunakan dalam kode tugas. Kode tugas secara eksplisit mendefinisikan metode train_step dalam subclass CustomTraining untuk mengendalikan pelatihan dengan tingkat kontrol yang lebih tinggi.\n",
        "\n",
        "Sementara dalam kode praktikum 2, pendekatan lebih sederhana menggunakan metode model.fit, di mana sebagian besar detail pelatihan diurus oleh framework TensorFlow secara otomatis, dan pengguna tidak perlu mendefinisikan secara eksplisit langkah-langkah seperti perhitungan gradien dan pembaruan bobot. Pendekatan ini lebih cocok untuk tugas-tugas pelatihan standar di mana tidak perlu melakukan kustomisasi tingkat rendah yang signifikan.\n",
        "\n",
        "Jadi, perbedaan tersebut mencerminkan fleksibilitas dan kontrol yang lebih besar yang dapat dicapai dengan pendekatan kustom, tetapi juga dengan biaya kompleksitas kode yang lebih tinggi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}